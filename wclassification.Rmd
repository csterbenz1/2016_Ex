---
title: "testing_wClassification"
author: "Ciara Sterbenz"
date: "3/17/2021"
output: pdf_document
---

```{r setup, include = F}
#rm(list = ls())
knitr::opts_chunk$set(echo = TRU
set.seed(9345876)

### Packages
library(MASS)
library(tidyverse)
library(survey)
library(kbal)
library(parallel)
library(knitr)
library(kableExtra)
library(glmnet)
library(xgboost)
library(caret)
```



```{r load_data}
PRE = TRUE
three_way = TRUE
path_data= "/Users/Ciara/Dropbox/kpop/application/data/"
# path_kbalruns = "/Users/Ciara/Documents/Cloud Documents/Hazlett:Hartman RA/2016 Election/"

# AUXILIARY INFORMATION (CCES)
cces <- readRDS(paste0(path_data, "cces_new.rds"))

### Drop invalid cases
##### SOON DROP NAS
cces <- cces %>%
    filter((CC16_401 == "I definitely voted in the General Election.") &
               !is.na(commonweight_vv_post) 
               ) %>% 
    mutate(commonweight_vv_post = commonweight_vv_post/ mean(commonweight_vv_post))
sum(is.na(cces$recode_vote_2016))


cces <- cces %>% mutate(recode_attndch_bin = 
                            factor(ifelse(recode_attndch_4way== "Never", "No", "Yes")))


cces <- cces %>% mutate(
    #36 levels
    recode_educ_pid_race = as.factor(paste(recode_educ_3way,
                                           recode_pid_3way, 
                                           recode_race, sep = ", ")),
    #12 levels
    recode_pid_race = as.factor(paste(recode_pid_3way, 
                                           recode_race, sep = ", ")),
    #9 levels
    recode_educ_pid = as.factor(paste(recode_educ_3way,
                                      recode_pid_3way, sep = ", ")),
    recode_agesq = recode_age*recode_age,
    recode_agecubed = recode_age*recode_age*recode_age,
    #13 levles
    recode_midwest_edu_race = as.factor(
        case_when(recode_region == "Midwest" ~ paste(recode_region,
                                                     recode_race,
                                                     recode_educ_3way, 
                                                     sep = ", "),
                  TRUE ~ "No Split")), 
    #4 levels ( low educated whites in midwest only)
    recode_midwest_wh_edu = factor(case_when(
        (recode_race != "White" | recode_region != "Midwest") ~ "No Split", 
        TRUE ~ as.character(recode_educ_3way)), 
        levels = c("No Split", "No College", "College", "Post-grad")), 
    recode_age_factor = factor(case_when(recode_age <92 ~ as.character(recode_age), 
                                         TRUE ~ "92+")) )



#ALL CURRENT KPOP RESULTS ARE NOT THESE INCLUDED
cces <- cces %>%
    filter(!is.na(recode_vote_2016))
```


# Approach 1: expanded dat + XGB (you could maybe still try this by doign a random sample)

```{r byhand}
test <- matrix(c(1,1,1,1,
                 2,2,2,2,
                 3,3,3,3), nrow = 3, ncol = 4, byrow = T)
w <- c(3,2,1)
#target
w*test
#replicate w repeated rows:
#number of rows will be sum of w (starting w whole numbers rn)
#ok we can do this w a lop and it will be slow af but for a start
expanded <- matrix(NA, nrow = sum(w), ncol = ncol(test))
start_index = 1
for(i in 1:length(w)) {
    # print(paste0("Iter: ", i))
    # print(start_index)
    # print(start_index:(start_index + w[i] -1))
    expanded[start_index:(start_index + w[i] -1),] <- test[i,]
    start_index <- sum(w[1:i]) +1
    
}
expanded
#hurrah
#non loop version bc R is trash
expanded <- matrix(NA, nrow = sum(w), ncol = ncol(test))
start_index = 1
ugh <- map(c(1:length(w)), function(i) {
    start_index <- ifelse(i ==1, 1, sum(w[1:i]) +1)
    expanded[start_index:(start_index + w[i] -1),] <- test[i,]
    
    return(expanded[start_index:(start_index + w[i] -1),])
})

ugh <- matrix(unlist(ugh), nrow = sum(w), ncol = ncol(test), byrow = T)


#ok so now let's figure out how to do this with non integeter weights ugh
#weights sum to N
w <- c(.5, .25, .25)
w <- w/mean(w)
sum(w)
w
#ok so now really what we want to do is have 2x the number of rows of 1st unit as compared to the second two.. How to get that to a whole number without using my brain
#does R have mod>? it does indeed, i gues we dont want mod we want the non remainder part
#but have to do this for all rows???? DEAR LORD
w[1] %/% w[2]
#no there's a basic arithmatic way to do this
1/min(w)
#that should give you what you have to multiply to get the min weight whole
min(w)*(1/min(w))
#so really it's just a matter of transforming the weight vector first and then doing the same thing

w_whole <- w*(1/min(w))
w_whole
expanded <- matrix(NA, nrow = sum(w), ncol = ncol(test))
start_index = 1
for(i in 1:length(w)) {
    # print(paste0("Iter: ", i))
    # print(start_index)
    # print(start_index:(start_index + w[i] -1))
    expanded[start_index:(start_index + w[i] -1),] <- test[i,]
    start_index <- sum(w[1:i]) +1
    
}
expanded

##### hurrah, ok how bad is this for cces
sum(is.na(cces$commonweight_vv_post))
#righto we dropped the nas so that's good
w <- cces$commonweight_vv_post
#oh nooo iut's gonna be HUUUGE
min(w)
#OH LORD
1/min(w)
w_whole <- w*(1/min(w))
#OH MY GOD
sum(w_whole)
# expanded <- matrix(NA, nrow = sum(w), ncol = ncol(test))
# start_index = 1
# for(i in 1:length(w)) {
#     # print(paste0("Iter: ", i))
#     # print(start_index)
#     # print(start_index:(start_index + w[i] -1))
#     expanded[start_index:(start_index + w[i] -1),] <- test[i,]
#     start_index <- sum(w[1:i]) +1
#     
# }
# expanded
w <- w_whole
expanded <- matrix(NA, nrow = sum(w), ncol = ncol(cces))
#lol yep NOOOOO


```


# Approach 2: Complex glm (2 way + logit)
```{r lasso_2way}
cces <- cces %>% mutate(recode_vote_2016_binary =
                            as.numeric(recode_vote_2016 == "Republican"))

#two way
pew <- pew %>% mutate(recode_vote_2016_binary =
                            as.numeric(recode_vote_2016 == "Republican"))

percent <- sample.int(nrow(cces), (nrow(cces)/10)*8)


#for lasso drop the NAs
cces <- cces %>%
    filter(!is.na(recode_vote_2016))

stack_data_train <- data.frame(bind_rows(pew, cces[percent,]), 
                         S = c(rep(1, nrow(pew)), rep(0, nrow(cces[percent,]))))

#base model is the selection model used in the sims
C_model = as.formula(~ recode_female + 
                         recode_pid_3way + 
                         recode_educ +
                         recode_income_5way + 
                         recode_relig_6way + 
                         recode_born + 
                         recode_attndch_4way +
                         recode_age +
                      I(recode_age^2) + 
                         recode_midwest_wh_edu + recode_race_educ_reg +
                         recode_female:recode_pid_3way + 
                         recode_age:recode_pid_3way )

mod <- model.matrix(C_model, data = stack_data_train)
ncol(mod)
# ## Remove columns where Pew missing strata
pew_cols <- apply(mod[stack_data$S == 1, ], 2, sum) != 0
mod <- mod[, pew_cols ]
## Remove columns where CCES missing Strata
cces_cols <-  apply(mod[stack_data$S == 0, ], 2, sum) != 0
mod <- mod[, cces_cols]
#the dropped columns appear to be the same in pew and cces... interesting
#wtf why do we drop mroe columns in selection mode than C model when its the same??
ncol(mod)
nrow(mod)

#lambda from 10 fold default CV
lasso_lambda <- cv.glmnet(x= mod[stack_data$S == 0,-1], 
                          y = cces$recode_vote_2016[percent],
                          alpha = 1,
                          family = "multinomial",
            weights = cces$commonweight_vv_post[percent],
                          intercept = TRUE)

lasso_cces <- glmnet(x= mod[stack_data$S == 0, -1], 
        y = cces$recode_vote_2016[percent],
                        alpha = 1,
                        lambda = lasso_lambda$lambda.1se,
                        family = "multinomial",
        weights = cces$commonweight_vv_post[percent],
                        intercept = TRUE)



lasso_vote_coefs <- coef(lasso_vote)
#lambda.1se drops 75/121 -> 87 with more coefs
sum(lasso_vote_coefs ==0)



############### pew model:


mod <- model.matrix(C_model, data = stack_data)
ncol(mod)
# ## Remove columns where Pew missing strata
mod <- mod[, apply(mod[stack_data$S == 1, ], 2, sum) != 0]
## Remove columns where CCES missing Strata
mod <- mod[, apply(mod[stack_data$S == 0, ], 2, sum) != 0]
#the dropped columns appear to be the same in pew and cces... interesting
#wtf why do we drop mroe columns in selection mode than C model when its the same??
ncol(mod)

lasso_lambda_pew <- cv.glmnet(x= mod[stack_data$recode_vote_2016 != "Other" & 
                                         stack_data$S == 1,-1], 
                          y = pew$recode_vote_2016_binary[pew$recode_vote_2016 != "Other"],
                          alpha = 1,
                          family = "binomial",
                          intercept = TRUE)

lasso_vote_pew <- glmnet(x= mod[stack_data$recode_vote_2016 != "Other" & 
                                         stack_data$S == 1, -1], 
        y = pew$recode_vote_2016_binary[pew$recode_vote_2016 != "Other"],
                        alpha = 1,
                        lambda = lasso_lambda_pew$lambda.1se,
                        family = "binomial",
                        intercept = TRUE)










```


# Approach 2: Complex glm (3 way + multinomial)
```{r lasso_3way}

#for lasso drop the NAs
cces <- cces %>%
    filter(!is.na(recode_vote_2016))
percent <- sample.int(nrow(cces), (nrow(cces)/10)*8)

stack_data_train <- data.frame(bind_rows(pew, cces[percent,]), 
                         S = c(rep(1, nrow(pew)), rep(0, nrow(cces[percent,]))))

#base model is the selection model used in the sims
C_model = as.formula(~ recode_female + 
                         recode_pid_3way + 
                         recode_educ +
                         recode_region +
                         recode_income_5way + 
                         recode_relig_6way + 
                         recode_born + 
                         recode_race +
                         recode_attndch_4way +
                         recode_age +
                      I(recode_age^2) + 
                         recode_female:recode_pid_3way + 
                         recode_age:recode_pid_3way + 
                         recode_educ:recode_pid_3way + 
                         recode_educ:recode_region)
mod <- model.matrix(C_model, data = stack_data_train)
ncol(mod)
nrow(mod)
nrow(stack_data_train)
# ## Remove columns where Pew missing strata
pew_cols <- apply(mod[stack_data_train$S == 1, ], 2, sum) != 0
mod <- mod[, pew_cols ]
## Remove columns where CCES missing Strata
cces_cols <-  apply(mod[stack_data_train$S == 0, ], 2, sum) != 0
mod <- mod[, cces_cols]
#the dropped columns appear to be the same in pew and cces... interesting
#wtf why do we drop mroe columns in selection mode than C model when its the same??
ncol(mod)
nrow(mod)

#lambda from 10 fold default CV
lasso_lambda_try <- cv.glmnet(x= mod[stack_data_train$S == 0,-1], 
                          y = cces$recode_vote_2016[percent],
                          alpha = 1,
                          family = "multinomial",
            weights = cces$commonweight_vv_post[percent],
                          intercept = TRUE)

lasso_cces_try <- glmnet(x= mod[stack_data_train$S == 0, -1], 
        y = cces$recode_vote_2016[percent],
                        alpha = 1,
                        lambda = lasso_lambda_try$lambda.1se,
                        family = "multinomial",
        weights = cces$commonweight_vv_post[percent],
                        intercept = TRUE)


###### Performance
stack_data_test <- data.frame(bind_rows(pew, cces[-percent,]), 
                         S = c(rep(1, nrow(pew)), rep(0, nrow(cces[-percent,]))))

mod_test <- model.matrix(C_model, data = stack_data_test)
#remove same columns as above
mod_test <- mod_test[, pew_cols]
## Remove columns where CCES missing Strata
mod_test <- mod_test[, cces_cols]
ncol(mod_test)

lasso_test = predict(lasso_cces_try,
                      s = lasso_lambda_try$lambda.1se,
                      type = "response",
                      newx = mod_test[stack_data_test$S==0,-1])

mod_test_plur <- apply(lasso_test,1, which.max)
mod_test_out <- factor(case_when(mod_test_plur-1 == 2 ~ 
                                                "Republican",
                                  mod_test_plur-1 == 1 ~ "Other", 
                                  mod_test_plur-1 == 0 ~ "Democrat"),
                               levels = c("Democrat", "Other", "Republican"))
outcome_test = cces$recode_vote_2016[-percent]
#overall correct
sum(mod_test_out == outcome_test)/length(outcome_test)
conf_cces_test <- confusionMatrix(as.factor(mod_test_out),
                                     as.factor(outcome_test))
cat("Confusion Matrix: CCES on CCES (Testing Data)\n")
print(t(t(conf_cces_test$table)/colSums(conf_cces_test$table)))

```


```{r}
#two way
cces <- cces %>% mutate(recode_vote_2016_binary =
                            as.numeric(recode_vote_2016 == "Republican"))
            Y_keep <- stack_data$recode_vote_2016 != "Other" & stack_data$S == 0
        
            ###################### LASSO ####################
            #lambda from 10 fold default CV
            lasso_lambda <- cv.glmnet(x= mod[Y_keep,-1], 
                                      y = cces$recode_vote_2016_binary[cces$recode_vote_2016 != "Other"],
                                      alpha = 1,
                                      family = "binomial",
                        weights = cces$commonweight_vv_post[cces$recode_vote_2016 != "Other"],
                                      intercept = TRUE)
            
            lasso_vote <- glmnet(x= mod[Y_keep, -1], 
                    y = cces$recode_vote_2016_binary[cces$recode_vote_2016 != "Other"],
                                    alpha = 1,
                                    lambda = lasso_lambda$lambda.1se,
                                    family = "binomial",
                    weights = cces$commonweight_vv_post[cces$recode_vote_2016 != "Other"],
                                    intercept = TRUE)
         
#### three way
 #lambda from 10 fold default CV
lasso_lambda <- cv.glmnet(x= mod[stack_data$S == 0,-1], 
                          y = cces$recode_vote_2016,
                          alpha = 1,
                          family = "multinomial",
            weights = cces$commonweight_vv_post,
                          intercept = TRUE)

lasso_vote <- glmnet(x= mod[stack_data$S == 0, -1], 
        y = cces$recode_vote_2016,
                        alpha = 1,
                        lambda = lasso_lambda$lambda.1se,
                        family = "multinomial",
        weights = cces$commonweight_vv_post,
                        intercept = TRUE)

```           


## XGB CCES RUN - 3WAY

```{r xgb_cces_3way}
outcome = cces$recode_vote_2016
#if want to keep NA
outcome[is.na(cces$recode_vote_2016)] = "Other"
out_int <- as.integer(as.factor(outcome))-1


#### 1: RUNNING XGB ON CCES 3WAY VOTE OUTCOME #####

cces_matrix_sparse <- cces %>%
    dplyr::select(recode_age,
           recode_female,
           recode_race,
           recode_region,
           recode_pid_3way,
           recode_educ,
           recode_income,
           #recode_relig has 38 Nas so need to use buckets
           recode_relig_6way,
           recode_born,
           #recode_attndch has some nas need to use buckegs
           recode_attndch_4way,
           recode_race_educ_reg) %>%
    sparse.model.matrix(as.formula("~."), .)

cces_matrix_sparse = cces_matrix_sparse[,-1]

#test
cces_matrix_sparse <- cces$common cces_matrix_sparse


percent <- sample.int(nrow(cces), (nrow(cces)/10)*8)
dat_xgb_train <- xgb.DMatrix(data = cces_matrix_sparse[percent,], 
                             label = out_int[percent])
dat_xgb_outofsamp <- xgb.DMatrix(data = cces_matrix_sparse[-percent,], 
                                 label = out_int[-percent])


#params (not cv'ed)
params = list(
    booster="gbtree",
    eta=0.3,
    max_depth=10,
    min_child_weight = 4,
    gamma=3,
    subsample= 0.7,
    colsample_bytree=1,
    objective="multi:softprob",
    num_class=3,
    eval_metric = "merror"
)

xgbcv <- xgb.cv( params = params,
                 data = dat_xgb_train,
                 nrounds = 500,
                 nfold = 5,
                 early_stopping_rounds = 50,
                 showsd = T,
                 stratified = T,
                 print_every_n = 10,
                 early_stop_round = 20,
                 maximize = F)

low_test  = which(xgbcv$evaluation_log$test_merror_mean == min(xgbcv$evaluation_log$test_merror_mean))
low_test
xgbcv$best_iteration

#run
xgb_cces =xgb.train(params=params,
                    data=dat_xgb_train,
                    nrounds= xgbcv$best_iteration,
                    watchlist = list(validation = dat_xgb_outofsamp),
                    nthreads=2,
                    print_every_n = 10)

#overfit version
# xgb_cces =xgb.train(params=params,
#                     data=dat_xgb_train,
#                     nrounds= 498,
#                     watchlist = list(validation = dat_xgb_outofsamp),
#                     nthreads=2,
#                     print_every_n = 10)



##### EVAL PERFORMANCE ####
xgb_outcome = predict(xgb_cces, dat_xgb_train, reshape=T)
xgb_outofsamp = predict(xgb_cces, dat_xgb_outofsamp, reshape =T)

#convert to max prob outcome:
xgb_plurality_train <- apply(xgb_outcome,1, which.max)
xgb_plurality_test <- apply(xgb_outofsamp,1, which.max)

sum(xgb_plurality_train -1 == out_int[percent])/length(out_int[percent])
sum(xgb_plurality_test - 1 == out_int[-percent])/length(out_int[-percent])

#rep = 2, dem = 0 other = 1
xgb_train_char = case_when(xgb_plurality_train  == 1 ~ "Democrat",
                           xgb_plurality_train  == 3 ~ "Republican",
                           xgb_plurality_train  == 2 ~ "Other")

xgb_test_char = case_when(xgb_plurality_test  == 1 ~ "Democrat",
                          xgb_plurality_test  == 3 ~ "Republican",
                          xgb_plurality_test  == 2 ~ "Other")
#check
sum(xgb_train_char == outcome[percent])/length(percent)
sum(xgb_test_char == outcome[-percent])/length(outcome[-percent])


#look at performance of plurality max:
conf_train = confusionMatrix(as.factor(xgb_train_char), 
                             as.factor(cces$recode_vote_2016)[percent])
conf_test = confusionMatrix(as.factor(xgb_test_char), 
                            as.factor(cces$recode_vote_2016)[-percent])

#because dividing rowwise is annoying:
print("Confusion Matrix: CCES 3way on CCES Training")
t(t(conf_train$table)/colSums(conf_train$table))
print("Confusion Matrix: CCES 3awayon CCES Testing")
t(t(conf_test$table)/colSums(conf_test$table))

```

# Run on Pew

```{r xgb_pew_3way}
 if(PRE) {
        pew <- readRDS(paste0(path_data, "pew_new.rds"))
        # #in pre: eliminate don't know plan to vote respondents:
        pew <- pew %>%
            filter(plan1 %in% c("Plan to vote", "Already voted"))
    } else {
        age_buckets = FALSE
        warning("with postwave, kpop weights are currently only without age buckets",
                immediate. = TRUE)
        pew <- readRDS(paste0(path_data, "pew_post_CS_q4.rds"))
    }
    
    pew <- pew %>% mutate(recode_attndch_bin = 
                            factor(ifelse(recode_attndch_4way== "Never", "No", "Yes")))
    
    pew <- bind_cols(pew, pew %>% 
                         unite("strata", all.vars(formula_ps), remove = FALSE) %>%
                         unite("strata_reduc", all.vars(formula_ps_reduc), 
                               remove = FALSE) %>%
                         unite("strata_all", all.vars(formula_ps_all)) %>%
                         dplyr::select(strata, strata_reduc, strata_all))

    #these are the strata in the population but not in the sample
    if(drop_ccesNAs) {
        cces <- cces %>% filter(!is.na(recode_vote_2016))
        if(!noDNK_weights) { warning("noDNK_weights must be true with no cces NAs",
                                     immediate. = T)}
        if(age_buckets) { warning("age_buckets must be true with no cces NAs",
                                     immediate. = T)}
        # if(popw) { warning("POPW must be false with no cces NAs",
        #                              immediate. = T)}
        noDNK_weights = TRUE
        age_buckets = FALSE
        #popw = FALSE
    }
    
    
    ##### RUN XGB on PEW ##################
    
    #this subsets cces strata to only those in pew
   
    missing_strata <- unique(cces$strata)[!(unique(cces$strata) %in%
                                                unique(pew$strata))]
    cat("% cces original strata missing from pew, ",
         length(missing_strata)/ length(unique(cces$strata)))
    missing_strata_reduc <- unique(cces$strata_reduc)[!(unique(cces$strata_reduc) %in%
                                                unique(pew$strata_reduc))]
    
     cat("% cces reduc strata missing from pew, ",length(missing_strata_reduc)/ length( unique(cces$strata_reduc)))
    missing_strata_all <- unique(cces$strata_all)[!(unique(cces$strata_all) %in%
                                                unique(pew$strata_all))]
     cat("% cces all strata missing from pew, ",length(missing_strata_all)/ length( unique(cces$strata_all)))
    
    #we also have the reverse where pew may have strata we don't have in cces
    #this arises if we eliminate NAs in recode_vote for cces
    #this ofc would never happen if cces was a true full pop but it's actually just
    #a much bigger sample so it can happen
     problem <- unique(pew$strata)[!(unique(pew$strata) %in%
                                                   unique(cces$strata))]
     problem_reduc <- unique(pew$strata_reduc)[!(unique(pew$strata_reduc) %in%
                                                   unique(cces$strata_reduc))]
     length(problem_reduc)
     problem_all <- unique(pew$strata_all)[!(unique(pew$strata_all) %in%
                                                   unique(cces$strata_all))]
     length(problem_all)
     if(length(problem) != 0) {
     warning(paste("NB: strata present in pew not in cces (3way)will be dropped in ps:\n",
                   problem, 
                   "\nrepresenting", nrow(pew %>% filter(strata %in% problem)),
                   "/", nrow(pew), "\n"), immediate. = TRUE)
     }
     if(length(problem_reduc) != 0) {
     warning(paste("NB: strata present in pew not in cces (3way)will be dropped in ps:\n",
                   "\nrepresenting", nrow(pew %>% filter(strata_reduc %in%
                                                             problem_reduc)),
                   "/", nrow(pew), "\n"), immediate. = TRUE)
     }
     if(length(problem_all) != 0) {
     warning(paste("NB: strata present in pew not in cces (3way)will be dropped in ps:\n",
                   "\nrepresenting", nrow(pew %>% filter(strata_all %in% problem_all)),
                   "/", nrow(pew), "\n"), immediate. = TRUE)
     }
    # need to actually drop it from pew for ps and all that to run correctly
    #note this also means we need to go and drop it from the kpop weights so 
    #i will keep track of the index
    #problem_index <- which(pew$strata %in% problem)
    #
    
    if(three_way) {
        pew_model_dat = pew
        classes = 3
    } else {
        pew_model_dat = pew[pew$recode_vote_2016 != "Other",]
        classes = 2
    }
    pew_outcome = pew_model_dat$recode_vote_2016
    pew_out_int <- as.integer(as.factor(pew_outcome))-1
    
    pew_matrix_sparse <- pew_model_dat %>%
        dplyr::select(recode_age,
               recode_female,
               recode_race,
               recode_region,
               recode_pid_3way,
               recode_educ,
               recode_income,
               #recode_relig has 38 Nas so need to use buckets
               recode_relig_6way,
               recode_born,
               #recode_attndch has some nas need to use buckegs
               recode_attndch_4way,
               recode_race_educ_reg) %>%
        sparse.model.matrix(as.formula("~."), .)
    
    pew_matrix_sparse = pew_matrix_sparse[,-1]
    
    
    pew_percent <- sample.int(nrow(pew_model_dat), (nrow(pew_model_dat)/10)*8)
    pew_dat_xgb_train <- xgb.DMatrix(data = pew_matrix_sparse[pew_percent,], 
                                     label = pew_out_int[pew_percent])
    pew_dat_xgb_outofsamp <- xgb.DMatrix(data =
                                             pew_matrix_sparse[-pew_percent,], 
                                         label = pew_out_int[-pew_percent])
    
    #using the same params as cces:
    params = list(
        booster="gbtree",
        eta=0.3,
        max_depth=10,
        min_child_weight = 4,
        gamma=3,
        subsample= 0.7,
        colsample_bytree=1,
        objective="multi:softprob",
        num_class= classes,
        eval_metric = "merror"
        )
    pew_xgbcv <- xgb.cv( params = params,
                         data = pew_dat_xgb_train, 
                         nrounds = 500,
                         nfold = 5, 
                         early_stopping_rounds = 50,
                         showsd = T, 
                         stratified = T, 
                         print_every_n = 10, 
                         early_stop_round = 20, 
                         maximize = F)
    
    low_test  = which(pew_xgbcv$evaluation_log$test_merror_mean ==
                          min(pew_xgbcv$evaluation_log$test_merror_mean))
    low_test
    pew_xgbcv$best_iteration
    
    #run
    xgb_pew =xgb.train(params=params,
                       data=pew_dat_xgb_train,
                       nrounds= pew_xgbcv$best_iteration,
                       watchlist = list(validation = pew_dat_xgb_outofsamp),
                       nthreads=2,
                       print_every_n = 10)
    
    
    pew_xgb_outcome = predict(xgb_pew, pew_dat_xgb_train, reshape=T)
    pew_xgb_outofsamp = predict(xgb_pew, pew_dat_xgb_outofsamp, reshape =T)
    
    #getting outcome with max prob
    pew_xgb_plurality_train <- apply(pew_xgb_outcome,1, which.max)
    pew_xgb_plurality_test <- apply(pew_xgb_outofsamp,1, which.max)
    
    sum(pew_xgb_plurality_train -1 == 
            pew_out_int[pew_percent])/length(pew_out_int[pew_percent])
    sum(pew_xgb_plurality_test - 1 == 
            pew_out_int[-pew_percent])/length(pew_out_int[-pew_percent])
    #rep = 2, dem = 0 other = 1
    if(three_way) {
         pew_xgb_train_char = factor(case_when(pew_xgb_plurality_train == 1
                                               ~ "Democrat",
                                          pew_xgb_plurality_train  == 3 
                                          ~ "Republican",
                                          pew_xgb_plurality_train  == 2 
                                          ~ "Other"),
                                levels = c("Democrat", "Other", "Republican"))
    
         pew_xgb_test_char = factor(case_when(pew_xgb_plurality_test  == 1 
                                              ~ "Democrat",
                                         pew_xgb_plurality_test  == 3 
                                         ~ "Republican",
                                         pew_xgb_plurality_test  == 2 
                                         ~ "Other"), 
                               levels = c("Democrat", "Other", "Republican"))
    } else {
        pew_xgb_train_char = factor(case_when(pew_xgb_plurality_train-1  == 0 
                                              ~ "Democrat",
                                            pew_xgb_plurality_train-1  == 1 
                                            ~ "Republican"),
                            levels = c("Democrat", "Republican"))


        pew_xgb_test_char = factor(case_when(pew_xgb_plurality_test-1  == 0 ~ "Democrat",
                                            pew_xgb_plurality_test-1  == 1 ~ "Republican"), 
                           levels = c("Democrat", "Republican"))
    }
   
    #check
    sum(pew_xgb_train_char == pew_outcome[pew_percent])/length(pew_percent)
    sum(pew_xgb_test_char == pew_outcome[-pew_percent])/length(pew_outcome[-pew_percent])
    
    pew_conf_train = confusionMatrix(as.factor(pew_xgb_train_char), 
                                as.factor(pew_model_dat$recode_vote_2016)[pew_percent])
    
    pew_conf_test = confusionMatrix(pew_xgb_test_char, 
                                as.factor(pew_model_dat$recode_vote_2016)[-pew_percent])
    cat("Confusion Matrix: Pew on Pew Training\n")
    print(t(t(pew_conf_train$table)/colSums(pew_conf_train$table)))
    cat("Confusion Matrix: Pew on Pew Testing\n")
    print(t(t(pew_conf_test$table)/colSums(pew_conf_test$table)))

```




# Post-Process

```{r predict_xgb}
 xgb_cces_mod = xgb_cces  
    
    ########  PREDICTING XBG CCES OUTCOME ###############
    #need full pew in case this is two way
    pew_matrix_all <- pew %>%
        dplyr::select(recode_age,
               recode_female,
               recode_race,
               recode_region,
               recode_pid_3way,
               recode_educ,
               recode_income,
               #recode_relig has 38 Nas so need to use buckets
               recode_relig_6way,
               recode_born,
               #recode_attndch has some nas need to use buckegs
               recode_attndch_4way,
               recode_race_educ_reg) %>%
        sparse.model.matrix(as.formula("~."), .)
        
    pew_matrix_all = pew_matrix_all[,-1]
    
     #with cces data, predict cces modeled outcome; must use full cces data regardless 
    #of model
    cces_matrix_all <- cces %>%
    dplyr::select(recode_age,
           recode_female,
           recode_race,
           recode_region,
           recode_pid_3way,
           recode_educ,
           recode_income,
           #recode_relig has 38 Nas so need to use buckets
           recode_relig_6way,
           recode_born,
           #recode_attndch has some nas need to use buckegs
           recode_attndch_4way,
           recode_race_educ_reg) %>%
    sparse.model.matrix(as.formula("~."), .)

    cces_matrix_all = cces_matrix_all[,-1]


    
    
    
    ######## PRED ON PEW #######
    ### 1. CCES ON PEW
    xgb_cces_on_pew = predict(xgb_cces_mod, pew_matrix_all, reshape=T)
    xgb_cces_on_pew_plur <- apply(xgb_cces_on_pew,1, which.max)
    sum(xgb_cces_on_pew_plur -1 == pew_out_int)/length(pew_out_int)
    #same thing just with characters to make confusion matrix easier to read
    if(three_way) {
         xgb_cces_on_pew_out <- case_when(xgb_cces_on_pew_plur-1 == 2 ~  "Republican",
                                     xgb_cces_on_pew_plur-1 == 1 ~ "Other", 
                                     xgb_cces_on_pew_plur-1 == 0 ~ "Democrat")
    } else {
        xgb_cces_on_pew_out <- case_when(xgb_cces_on_pew_plur-1 == 1 ~  "Republican",
                                 xgb_cces_on_pew_plur-1 == 0 ~ "Democrat")
    }
    #includes predictions on others forced to be binary in two-way
    #if want only on modeled data use pew_model_dat (makes no difference for three way)
    sum(xgb_cces_on_pew_out == pew$recode_vote_2016)/nrow(pew)
    conf_pew <- confusionMatrix(as.factor(xgb_cces_on_pew_out), 
                                as.factor(pew$recode_vote_2016))
    cat("Confusion Matrix: CCES on Pew (All Data)\n")
    print(t(t(conf_pew$table)/colSums(conf_pew$table)))
    
    ### 2. PEW ON PEW
    #with pew data, predict pew modeled outcome
    xgb_pew_on_pew = predict(xgb_pew, pew_matrix_all, reshape=T)
    xgb_pew_on_pew_plur <- apply(xgb_pew_on_pew,1, which.max)
    #this only works for three waty for two way need to adjust length of xgb_pew_on_pew
    #sum(xgb_pew_on_pew_plur -1 == pew_out_int)/length(pew_out_int)
    
    if(three_way) {
        xgb_pew_on_pew_out <- factor(case_when(xgb_pew_on_pew_plur-1 == 2 ~
                                                   "Republican",
                                           xgb_pew_on_pew_plur-1 == 1 ~ "Other", 
                                           xgb_pew_on_pew_plur-1 == 0 ~ "Democrat"),
                                 levels = c("Democrat", "Other", "Republican"))
    } else {
        xgb_pew_on_pew_out <- factor(case_when(xgb_pew_on_pew_plur-1 == 1 ~  "Republican",
                                       xgb_pew_on_pew_plur-1 == 0 ~ "Democrat"),
                             levels = c("Democrat", "Republican"))
    }
    #evaluating the performance on all pew data
    #for two way this means all those Other will be wrong automatically
    sum(xgb_pew_on_pew_out == pew$recode_vote_2016)/nrow(pew)
    conf_pew_pew <- confusionMatrix(xgb_pew_on_pew_out, 
                                    as.factor(pew$recode_vote_2016))
    cat("Confusion Matrix: Pew on Pew (All Data)\n")
    print(t(t(conf_pew_pew$table)/colSums(conf_pew_pew$table)))
    
    ####### PRED ON CCES ######
    ### 3. PEW on CCES
    xgb_pew_on_cces = predict(xgb_pew, cces_matrix_all, reshape=T)
    xgb_pew_on_cces_plur <- apply(xgb_pew_on_cces,1, which.max)
    #need to run xgb cces first for this to work (out_int definted)
    #sum(xgb_pew_on_cces_plur -1 == out_int)/length(out_int)
    
    if(three_way) {
        xgb_pew_on_cces_out <- factor(case_when(xgb_pew_on_cces_plur-1 == 2 ~
                                             "Republican",
                                     xgb_pew_on_cces_plur-1 == 1 ~ "Other", 
                                     xgb_pew_on_cces_plur-1 == 0 ~ "Democrat"), 
                                      levels = c("Democrat", "Other", "Republican"))
    } else {
        xgb_pew_on_cces_out <- case_when(xgb_pew_on_cces_plur-1 == 1 ~
                                             "Republican",
                                 xgb_pew_on_cces_plur-1 == 0 ~ "Democrat")
    }
    #to get these perecents just use full otucome where NAs are cosidered other
    outcome <- cces$recode_vote_2016
    outcome[is.na(outcome)] <- "Other"
    sum(xgb_pew_on_cces_out == outcome)/length(outcome)
    conf_pew_on_cces <- confusionMatrix(as.factor(xgb_pew_on_cces_out),
                                        as.factor(outcome))
    cat("Confusion Matrix: Pew on CCES (All Data)\n")
    print(t(t(conf_pew_on_cces$table)/colSums(conf_pew_on_cces$table)))
    
    
    #### 4. CCES ON CCES
    #(this could be done outside the function but it's nice to keep it all together for
    #2 and 3 way keeping track)
    ### CCES ON CCES
    xgb_cces_on_cces = predict(xgb_cces_mod, cces_matrix_all, reshape=T)
    
    xgb_cces_on_cces_plur <- apply(xgb_cces_on_cces,1, which.max)
    # sum(xgb_cces_on_cces_plur -1 == out_int)/length(out_int)
    if(three_way) {
       xgb_cces_on_cces_out <- factor(case_when(xgb_cces_on_cces_plur-1 == 2 ~ 
                                                    "Republican",
                                      xgb_cces_on_cces_plur-1 == 1 ~ "Other", 
                                      xgb_cces_on_cces_plur-1 == 0 ~ "Democrat"), 
                                      levels = c("Democrat", "Other", "Republican"))
    } else {
         xgb_cces_on_cces_out <- case_when(xgb_cces_on_cces_plur-1 == 1 ~  "Republican",
                                      xgb_cces_on_cces_plur-1 == 0 ~ "Democrat")
    }
   
    sum(xgb_cces_on_cces_out == outcome)/length(outcome)
    conf_cces_on_cces <- confusionMatrix(as.factor(xgb_cces_on_cces_out),
                                         as.factor(outcome))
    cat("Confusion Matrix: CCES on CCES (All Data)\n")
    print(t(t(conf_cces_on_cces$table)/colSums(conf_cces_on_cces$table)))

    
    ################### POST PROCESS #######################
    #max prob is
    xgb_cces_on_pew_plur <- apply(xgb_cces_on_pew,1, max)
    xgb_pew_on_pew_plur <- apply(xgb_pew_on_pew,1, max)
    
    if(three_way) {
        #prob rep
        xgb_cces_on_pew_pR <- xgb_cces_on_pew[,3]
        xgb_pew_on_pew_pR <- xgb_pew_on_pew[,3]
        
        #prob dem
        xgb_cces_on_pew_pD <- xgb_cces_on_pew[,1]
        xgb_pew_on_pew_pD <-  xgb_pew_on_pew[,1]
        
        #prob other
        xgb_cces_on_pew_pO <- xgb_cces_on_pew[,2]
        xgb_pew_on_pew_pO <-  xgb_pew_on_pew[,2]
    } else {
        #prob rep
        xgb_cces_on_pew_pR <- xgb_cces_on_pew[,2]
        xgb_pew_on_pew_pR <- xgb_pew_on_pew[,2]

        #prob dem
        xgb_cces_on_pew_pD <- xgb_cces_on_pew[,1]
        xgb_pew_on_pew_pD <-  xgb_pew_on_pew[,1]
    }
    
    #individual level margins
    margin_cces_on_pew = (xgb_cces_on_pew_pD - xgb_cces_on_pew_pR)/ 
        (xgb_cces_on_pew_pR + xgb_cces_on_pew_pD)
    margin_pew_on_pew = (xgb_pew_on_pew_pD- xgb_pew_on_pew_pR)/
        (xgb_pew_on_pew_pR + xgb_pew_on_pew_pD)
    #indiv level diff
    diff_cces_on_pew = xgb_cces_on_pew_pD - xgb_cces_on_pew_pR
    diff_pew_on_pew = xgb_pew_on_pew_pD- xgb_pew_on_pew_pR
    
    pew_xgb <- cbind(pew, 
                     xgb_cces_on_pew_out, 
                     xgb_pew_on_pew_out,
                     xgb_cces_on_pew_plur,
                     xgb_pew_on_pew_plur,
                     xgb_cces_on_pew_pR,
                     xgb_pew_on_pew_pR,
                     xgb_cces_on_pew_pD,
                     xgb_pew_on_pew_pD,
                     margin_cces_on_pew,
                     margin_pew_on_pew,
                     diff_cces_on_pew,
                     diff_pew_on_pew) 
 
    if(three_way) {
        pew_xgb <- cbind(pew_xgb, 
                         xgb_cces_on_pew_pO, xgb_pew_on_pew_pO)
    }
    
    pew_srs_xgb <- svydesign(ids = ~1, data = pew_xgb)
    pew_w_srs <-  svydesign(ids = ~1, weights = ~weight, data = pew_xgb)
    
    ### CCES:
    
    #max prob is
    xgb_cces_on_cces_plur <- apply(xgb_cces_on_cces,1, max)
    xgb_pew_on_cces_plur <- apply(xgb_pew_on_cces,1, max)
    
    if(three_way) {
        #prob rep
        xgb_cces_on_cces_pR <- xgb_cces_on_cces[,3]
        xgb_pew_on_cces_pR <- xgb_pew_on_cces[,3]
        
        #prob dem
        xgb_cces_on_cces_pD <- xgb_cces_on_cces[,1]
        xgb_pew_on_cces_pD <-  xgb_pew_on_cces[,1]
        
        #prob dem
        xgb_cces_on_cces_pO <- xgb_cces_on_cces[,2]
        xgb_pew_on_cces_pO <-  xgb_pew_on_cces[,2]
        
    } else {
        #prob rep
        xgb_cces_on_cces_pR <- xgb_cces_on_cces[,2]
        xgb_pew_on_cces_pR <- xgb_pew_on_cces[,2]
        
        #prob dem
        xgb_cces_on_cces_pD <- xgb_cces_on_cces[,1]
        xgb_pew_on_cces_pD <-  xgb_pew_on_cces[,1]
    }
    
    margin_cces_on_cces = (xgb_cces_on_cces_pD - xgb_cces_on_cces_pR)/ 
        (xgb_cces_on_cces_pR + xgb_cces_on_cces_pD)
    margin_pew_on_cces = (xgb_pew_on_cces_pD - xgb_pew_on_cces_pR)/ 
        (xgb_pew_on_cces_pR + xgb_pew_on_cces_pD)
   
    diff_cces_on_cces = xgb_cces_on_cces_pD - xgb_cces_on_cces_pR
    diff_pew_on_cces = xgb_pew_on_cces_pD - xgb_pew_on_cces_pR
    
    cces_xgb <- cbind(cces, 
                      xgb_cces_on_cces_out,
                      xgb_pew_on_cces_out,
                      xgb_cces_on_cces_plur,
                      xgb_pew_on_cces_plur,
                      xgb_cces_on_cces_pD,
                      xgb_pew_on_cces_pD,
                      xgb_cces_on_cces_pR,
                      xgb_pew_on_cces_pR,
                      margin_cces_on_cces,
                      margin_pew_on_cces,
                      diff_cces_on_cces,
                      diff_pew_on_cces)
    if(three_way) {
        cces_xgb <- cbind(cces_xgb, xgb_cces_on_cces_pO, xgb_pew_on_cces_pO)
    }
    
```

```{r predict_lasso}
# lasso_pvote = predict(lasso_vote,
#                       s= lasso_lambda_try$lambda.1se,
#                       type = "response",
#                       newx = mod[stack_data$S==0,-1])
# 
# #########
# # ## Add simulated results to CCES data
# cces <- cces %>%
#   mutate(lasso_cces_on_cces_pD = 1- lasso_pvote, 
#          lasso_cces_on_cces_pR = lasso_pvote) %>% 
#     mutate(lasso_cces_on_cces_diff = lasso_cces_on_cces_pD - lasso_cces_on_cces_pR, 
#            lasso_cces_on_cces_margin = (lasso_cces_on_cces_pD -
#                                             lasso_cces_on_cces_pR)/(lasso_cces_on_cces_pD +
#                                                                         lasso_cces_on_cces_pR) )

stack_data_all <- data.frame(bind_rows(pew, cces), 
                         S = c(rep(1, nrow(pew)), rep(0, nrow(cces))))


mod_all <- model.matrix(C_model, data = stack_data_all)
mod_all <- mod_all[, pew_cols ]
mod_all <- mod_all[, cces_cols]
nrow(mod_all[stack_data_all$S==0,-1])
nrow(cces)
lasso_pvote_3way = predict(lasso_cces_try,
                      s= lasso_lambda_try$lambda.1se,
                      type = "response",
                      newx = mod_all[stack_data_all$S==0,-1])



cces_temp <- cces %>%
  mutate(lasso_cces_on_cces_pD = lasso_pvote_3way[,"Democrat",], 
         lasso_cces_on_cces_pR = lasso_pvote_3way[,"Republican",]) %>% 
    mutate(lasso_cces_on_cces_diff = lasso_cces_on_cces_pD - lasso_cces_on_cces_pR, 
           lasso_cces_on_cces_margin = (lasso_cces_on_cces_pD -
                                            lasso_cces_on_cces_pR)/(lasso_cces_on_cces_pD +
                                                                        lasso_cces_on_cces_pR) )


```


# Performance

```{r}

vote_contrast <- quote((recode_vote_2016Democrat - recode_vote_2016Republican) /
                               (recode_vote_2016Democrat + recode_vote_2016Republican))

vote_diff <- quote((recode_vote_2016Democrat - recode_vote_2016Republican) /(recode_vote_2016Democrat + recode_vote_2016Republican + recode_vote_2016Other)) 



############## Lasso weighted:
vote_form = vote_diff
var_orig = "recode_vote_2016"
var_cces = "lasso_cces_on_cces_diff"
cces_awt <- svydesign(ids = ~1, weights = ~commonweight_vv_post, 
                              data = cces_temp)
cces_nowt <- svydesign(ids = ~1, data = cces_temp)
cces_svy = cces_awt
cces_orig = svycontrast(svymean(as.formula(paste0("~", var_orig)), 
                                            cces_svy, na.rm = TRUE),
                                    vote_form)
#t
cces_lasso = svymean(as.formula(paste0("~", var_cces)), cces_svy, na.rm = TRUE)
#
cces_orig*100 - cces_lasso*100
#with niether we are .4 off
#wtih only midwest we are 0.38 off
#with only race educ region we are .38 off
#with both we are .3866 off lol
#HURRAH!
```
