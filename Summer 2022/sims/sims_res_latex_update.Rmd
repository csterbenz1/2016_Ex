---
title: "Kpop Simulation Results"
output: pdf_document
header-includes:
  - \usepackage{graphicx}
  - \usepackage{booktabs}
  - \usepackage{makecell}
  - \usepackage{xcolor}
---

```{r libs, include =F, message=FALSE, warning= F}
suppressMessages(library(tidyverse))
library(parallel)
suppressMessages(library(knitr))
library(kableExtra)
library(survey)
```

```{r filenames, include = F}
r33_file_lin = "~/Documents/Cloud Documents/Hazlett:Hartman RA/2016 Election/2016_Ex/Summer 2022/sims/noscale_res_kpopTRUE_noise1.414_on2022-11-16_nsims494.RData"
r66_file_lin= "~/Documents/Cloud Documents/Hazlett:Hartman RA/2016 Election/2016_Ex/Summer 2022/sims/noscale_res_kpopTRUE_noise0.707_on2022-11-16_nsims494.RData"
r66_bern_file_lin  = "~/Documents/Cloud Documents/Hazlett:Hartman RA/2016 Election/2016_Ex/Summer 2022/sims/noscale_res_kpopTRUE_noise0.707_on_bernTRUE_2022-11-16_nsims494.RData"

r66_file = "~/Documents/Cloud Documents/Hazlett:Hartman RA/2016 Election/2016_Ex/Summer 2022/sims/noscale_kpopTRUE_noise0.707106781186548_on2022-12-09_nsims338.RData"

```


```{r functions, include = F}
coverage <- function(SE, x_bar, truth, crit_val= qnorm(0.975)) {
    x_upper = x_bar +  (SE*crit_val)
    x_lower = x_bar - (SE*crit_val)
    contains_truth = matrix(NA, ncol = ncol(SE), nrow = 1)
    for(i in 1:ncol(x_upper)) {
        contains_truth[,i] = sum((truth <= x_upper[,i] & truth >= x_lower[,i]))/nrow(SE)
    }
    colnames(contains_truth) = colnames(x_bar)
    return(contains_truth)
}

# eval coverage of diff SEs
all_SE_coverage <- function(sims, drop_NA = F, truth, methods = c("rake|kpop"), SEs_overwrite = NULL) {
    est <- lapply(sims, `[[`, 1) %>% bind_rows()
    SEs <- lapply(sims, `[[`, 2) %>% bind_rows()
    if(!is.null(SEs_overwrite)) {SEs = SEs_overwrite }
    if(drop_NA) {
        est_temp = na.omit(est)
        n_drop = nrow(est) - nrow(est_temp)
        est = est_temp
        SEs = na.omit(SEs)
    }
    
    est_c = est[grepl(methods, colnames(est))]
    SE_fixed = SEs[grepl("SE_fixed$", colnames(SEs))]
    SE_linear = SEs[grepl("SE_linear$", colnames(SEs))]
    SE_quasi = SEs[grepl("SE_quasi$", colnames(SEs))]
    SE_chad= SEs[grepl("SE_chad$", colnames(SEs))]
    
    SE_svy= SEs[grepl("SVY", colnames(SEs))]
    if(ncol(SE_svy) != 0){
        #just making sure we're getting the estimates for the same SEs that we output from svy obj which currently is demos_noedu
        search = gsub("_se_SVY","", colnames(SE_svy))
        s = coverage(SE_svy, est_c[,grepl(search, colnames(est_c))], truth = truth)
        s1 = rep(NA, ncol(SE_fixed))
        s1[grepl(search, colnames(est_c))] = s
        #colnames(s1) = colnames(SE_fixed)
        coverage_out = rbind(coverage(SE_fixed, est_c, truth = truth),
                             coverage(SE_linear, est_c, truth = truth),
                             coverage(SE_quasi, est_c,truth = truth),
                             coverage(SE_chad,est_c,truth = truth), 
                             s1)
        rownames(coverage_out) = c("SE_fixed", "SE_linear", "SE_quasi", "SE_chad", "SE_svy")
    } else {
        coverage_out = rbind(coverage(SE_fixed, est_c, truth = truth),
                             coverage(SE_linear, est_c, truth = truth),
                             coverage(SE_quasi, est_c,truth = truth),
                             coverage(SE_chad,est_c,truth = truth))
        rownames(coverage_out) = c("SE_fixed", "SE_linear", "SE_quasi", "SE_chad")
    }
    
    
    if(drop_NA) {
        out = list()
        out$n_drop = n_drop
        out$coverage = coverage_out
    } else {
        out = coverage_out
    }
    return(out)
}

manual_rescale <- function(dat, a =0, b= 1) {
    rescaled = (b-a)*( dat - min(dat))/(max(dat) - min(dat)) + a
    return(rescaled)
}



```



```{r outcome, include = F}
###### SET PARAMS  ###############
make_outcome <- function(noise, bern = F, selection_coefs = NULL, outcome_coefs = NULL, POPW = FALSE, 
                         coverage_eval = TRUE, linear_model = FALSE) {
    #have to copy paste everything from the sims bc didn't set seed right before noise added UGHUGHGU
    set.seed(9345876)

    if(detectCores() > 10) {
      path_data = "/home/csterbenz/Data/"
      cores_saved = 10
    } else if(detectCores() != 4) {
      path_data= "/Users/Ciara_1/Dropbox/kpop/Updated/application/data/"
      cores_saved = 6
    } else {
        path_data= "/Users/Ciara/Dropbox/kpop/Updated/application/data/"
        cores_saved = 2
    }
    
    POPW = FALSE
    bern = FALSE
    coverage_eval = TRUE
    linear_model_unused = FALSE # jsut to not write over the input but keep seed the same
    noise_unused = (1/2)*sqrt(2)
    TEST = FALSE # to run with a linear kernel so it's way faster; UPDATE: errors catch this as mistake and prevent
    tolerance = 1e-4
    maxit = 500
    #both for runtime
    increment = 5
    min_num_dims = NULL
    max_num_dims = NULL
    SAVE = TRUE
    ##### Central Params to adjust
    n_sample = 500
    simple_selection_model = TRUE
    nsims = (detectCores()-cores_saved)*13
    nsims
    ###################### Formulas ################
    formula_rake_demos_noeduc <- ~recode_age_bucket + recode_female + recode_race +
      recode_region + recode_pid_3way
    
    #updated to include 6 way edu
    formula_rake_demos_weduc <- ~recode_age_bucket + recode_female +
      recode_race + recode_region + recode_educ + recode_pid_3way
    
    formula_rake_all_vars <- ~recode_age_bucket + recode_female +
      recode_race + recode_region + recode_pid_3way + recode_educ +
      recode_income_5way + recode_relig_6way + recode_born + recode_attndch_4way
    
    formula_ps <- ~recode_age_3way + recode_female + recode_race +
      recode_region + recode_educ_wh_3way + recode_pid_3way
    
    # if(coverage_eval &!linear_model) {
    #     formula_ps <- ~recode_age_3way + recode_female + recode_pid_3way
    # } else if(coverage_eval) {
    #     formula_ps <- ~recode_age_3way + recode_pid_3way
    # }
    
    formula_ps_reduc <- ~recode_age_3way + recode_female +
      recode_race + recode_region + recode_pid_3way  +
      recode_income_3way + recode_born + recode_educ_wh_3way
    
    # #let's coarsen income and religion and attend church for all:
    formula_ps_all <- ~recode_age_3way + recode_female +
      recode_race + recode_region + recode_pid_3way + recode_educ_3way +
      recode_income_3way + recode_relig_6way + recode_born + recode_attndch_bin
    
    create_targets <- function (target_design, target_formula) {
      target_mf <- model.frame(target_formula, model.frame(target_design))
      target_mm <- model.matrix(target_formula, target_mf)
      wts <- weights(target_design)
    
      return(colSums(target_mm * wts) / sum(wts))
    }
    
    manual_rescale <- function(dat, a =0, b= 1) {
        rescaled = (b-a)*( dat - min(dat))/(max(dat) - min(dat)) + a
        return(rescaled)
    }
    
    ### Post-stratification function
    ## For now assumes that strata variable is already created and in
    ## the data set and called "strata"
    postStrat <- function(survey, pop_counts, pop_w_col, strata_pass, warn = T) {
      survey_counts <- survey %>%
        group_by(!!as.symbol(strata_pass)) %>%
        summarize(n = n()) %>%
        ungroup() %>%
        mutate(w_survey = n / sum(n))
    
      pop_counts <- pop_counts %>%
        rename(w_pop = matches(pop_w_col))
      
      if(warn == T & nrow(survey_counts) !=  nrow(pop_counts)) {
          missing_strat = pop_counts[! (( pop_counts[, strata_pass]%>% pull()) %in% (survey_counts[, strata_pass]%>% pull() )), strata_pass]
          warning(paste("Strata in Pop not found in Sample. Dropping", 
                        sum(pop_counts[(pop_counts[, strata_pass] %>% pull()) %in% 
                                           (missing_strat %>% pull()),"n" ]), 
                        "empty cells\n"), immediate.  =T )
      } 
    
      post_strat <- pop_counts %>%
        left_join(survey_counts, by = strata_pass) %>%
        filter(!is.na(w_survey)) %>%
        ## Normalizes back to 1 after dropping
        ## empty cells
        mutate(w_pop = w_pop * 1/sum(w_pop),
               w = w_pop / w_survey) %>%
        dplyr::select(!!as.symbol(strata_pass), w)
    
      survey <- survey %>%
        left_join(post_strat)
    
      return(survey)
    }
    check_sample <- function(sample, selection_model) {
        check = model.matrix(selection_model, data = sample)
        check = colSums(check)
        fail = check[which(check ==0)]
        if(length(fail) ==0) {
            return(NULL)
        } else {
            return(fail)
        }
    }
    check_outcome <- function(outcome) {
        beyond_support = (min(outcome) <0 | max(outcome) > 1)
        return(beyond_support)
    }
    
    bound_outcome <- function(outcome, coefs, increment = 1, increment_intercept = .01, noise, cces_expanded, silent = T) {
        denom = 10
        fail = check_outcome(outcome)
        while(fail) {
            denom = denom + increment
            if(!silent) { cat(denom, ": ") }
            coefs_use = coefs/denom
            outcome = cces_expanded %*% coefs_use
            
            outcome = outcome + rnorm(nrow(cces_expanded), mean = 0, sd = sd(outcome)*noise)
            summary(outcome)
            if(max(outcome) <=1 & min(outcome) <0 ) {
                coefs[1] = coefs[1] + increment_intercept
                if(!silent) { cat("\nmoving intercept up", coefs[1],  "\n") }
                denom = denom - increment
            }
            if(max(outcome) >1 & min(outcome) >=0 ) {
                coefs[1] = coefs[1] - increment_intercept
                if(!silent) { cat("\nmoving intercept down", coefs[1],  "\n") }
                denom = denom - increment
            }
            fail = check_outcome(outcome)
            if(!silent) { cat(round(min(outcome),2), round(max(outcome),2),  "\n") }
        }
        if(!silent) { cat(paste("Min denom:", denom)) }
        return(list(outcome = outcome, coefs = coefs_use, denom = denom))
        
    }
    
    
    ############# Load Data #####################
    #these data have been cleaned already see app_modeled for how it was done
    ## Load Pew
    pew <- readRDS(paste0(path_data, "pew_lasso_061021.rds"))
    
    
    ### Load Target Data
    cces <- readRDS(paste0(path_data, "cces_lasso_061021.rds"))
    
    ################# Selection Model and Outcome Model ###########
    if(!coverage_eval) {

        if(simple_selection_model) {
            #first attempt to make this worse
            selection_model = as.formula(~recode_pid_3way:poly(recode_age, 2) +
                                             recode_female:recode_pid_3way)
            #first attempt to make this worse
            #center age then square
            pew = pew %>% mutate(centered_age = scale(recode_age, scale = F))
            cces = cces %>% mutate(centered_age = scale(recode_age, scale = F))
    
            selection_model = as.formula(~recode_pid_3way*poly(centered_age, 2) +
                                             #recode_age:recode_pid_3way +
                                             recode_female*recode_pid_3way)
    
            #selection_model = as.formula(~recode_pid_3way + recode_age_bucket + recode_female)
    
        } else {
            selection_model = as.formula(~recode_female:recode_pid_3way +
                                             recode_age:recode_pid_3way +
                                             #adds a bit mroe bias to edu+d
                                             recode_pid_race +
                                             recode_race_reg_wh_educ +
                                             recode_educ_wh_3way +
                                             poly(recode_age, 3))
        }
        # Stack data with S = 1 indicating Pew
        stack_data <- data.frame(bind_rows(pew, cces),
                                 S = c(rep(1, nrow(pew)), rep(0, nrow(cces))))
    
    
        mod <- model.matrix(selection_model, data = stack_data)
        nrow(mod)
        ## Remove columns where Pew missing strata
        ncol(mod)
        mod <- mod[, apply(mod[stack_data$S == 1, ], 2, sum) != 0]
        ## Remove columns where CCES missing Strata
        mod <- mod[, apply(mod[stack_data$S == 0, ], 2, sum) != 0]
        ncol(mod)
        lasso_lambda <- cv.glmnet(x= mod[,-1],
                                  y = as.matrix(stack_data$S),
                                  alpha = 1,
                                  family = "binomial",
                                  intercept = TRUE)
        lasso_lambda$lambda.min
        lasso_include <- glmnet(x= mod[,-1],
                                y = as.matrix(stack_data$S),
                                alpha = 1,
                                lambda = lasso_lambda$lambda.min,
                                weights = if(POPW){ c(rep(1, nrow(pew)),
                                                      cces$commonweight_vv_post)} else {NULL},
                                family = "binomial",
                                intercept = TRUE)
    
        lasso_include_coefs <- coef(lasso_include)
        res <- as.matrix(lasso_include_coefs)
        #View(res)
        ncol(mod)
        sum(lasso_include_coefs == 0)
    
        lasso_include_coefs
        lasso_pinclude = predict(lasso_include,
                                 s= lasso_lambda$lambda.min,
                                 type = "response",
                                 newx = mod[stack_data$S == 0,-1])
    
        p_include <- lasso_pinclude
        sum(p_include)
        cor(p_include, cces$outcome)
        cor(p_include, cces$mod_cces_on_cces_pD)
        cor(p_include, cces$mod_cces_on_cces_pR)
    
        ########### Sampling Inclusion Results
        summary(p_include)
        sum(p_include)
        mean(p_include)
        p_include_raw = p_include
    
    
        intercept_shift = 0
        p_include = p_include*(n_sample/sum(p_include)) + intercept_shift
        mean(p_include)
        summary(p_include)
        sum(p_include)
    
        #################### Define Outcome #########
        cces$outcome = cces$diff_cces_on_cces
    } else {
        if(linear_model) {
            ########## DESIGN SELECTION MODEL: Specifying Coefs Directly
            #coefs: pid, age, gender
            selection_model = as.formula(~recode_pid_3way + recode_age_bucket + recode_female)
            cces_expanded = model.matrix(selection_model, data = cces)
            #needs to be n x p X p x 1 -> coef matrix is p x 1
            coefs = matrix(NA,nrow = ncol(cces_expanded), ncol =1 )
            rownames(coefs) = colnames(cces_expanded)
            coefs[,1] = c(-5.2, #intercept
                          .1, #selection of indep pos
                          .4, #selection of R pos
                          .1, #36-50,
                          .3, #51-64,
                          .8, #65+,
                          .4 #male pos
            )
            
            xbeta = cces_expanded %*% coefs
            p_include = plogis(xbeta)
            sum(p_include)
            summary(p_include)
            
            #################### DESIGN OUTCOME MODEL ##################
            coefs_outcome = coefs
            
            coefs_outcome[,1] = c(6.1, #intercept
                                  -.3, #  indep pos #decreasing lowers mean, increases corr #try 1
                                  -1.1, #  R pos #empirically
                                  -.2 ,#36-50, #empirically in cces lean dem 50% #.55
                                  -.3, #51-64, #empirically lean rep slightly 50%
                                  -.7, #65+, #empirically lean rep 51%
                                  #base cat: 18-35 lean strongly dem 58%
                                  -.7 #male #empirically women lean dem 53%
            )
            coefs_outcome = coefs_outcome/10
            
            xbeta_outcome = cces_expanded %*% coefs_outcome
            
            if(!bern) {
                cat(paste("(linear) Adding sd(outcome)*",round(noise, 3), "\n"))   
                xbeta_outcome = xbeta_outcome + rnorm(nrow(cces), mean = 0, sd = sd(xbeta_outcome)*noise)
            }
            if(bern) {
                cat(paste("(linear) Adding bernoulli ### UPDATE ###",round(noise, 3), "\n"))  
                xbeta_outcome = rbinom(nrow(cces), 1, xbeta_outcome) 
            }
            cat(paste("Range of outcome w/noise is\n"))
            cat(paste(summary(xbeta_outcome), "\n"))
            if(min(xbeta_outcome) <0 | max(xbeta_outcome) > 1) {warning("outcome beyond prob support for some units when noise is added", immediate. = T)}
            s = summary(lm(xbeta_outcome ~ recode_pid_3way + recode_age_bucket + recode_female,data = cces))
            R2_outcome = s$adj.r.squared
            cat(paste("R^2 outcome is", round(s$adj.r.squared,3), "\n"))
            cat(paste("Mean scaled outcome (target) is", round(mean(xbeta_outcome)*100,3)))
            cat(paste("\nCorr of sampling prob and outcome ", round(cor(xbeta_outcome, p_include),3)))
            #bernoulli draw
            coefs_outcome_out = coefs_outcome
            cces$outcome = xbeta_outcome
    } else {
        
        selection_model = as.formula(~recode_pid_3way +recode_female + recode_age_bucket + recode_educ_3way + 
                                     +     recode_pid_3way:recode_age_bucket
                                     # +recode_age:recode_pid_3way +
                                     #recode_female*recode_pid_3way
        )
        cces_expanded = model.matrix(selection_model, data = cces)
        coefs = matrix(NA,nrow = ncol(cces_expanded), ncol =1 )
        rownames(coefs) = colnames(cces_expanded)
        coefs
        #(p(S)) for negative bias select non dem voters
        coefs[,1] = c(-7.7, #intercept -5 w race
                      2, #selection of indep pos
                      3, #selection of R pos
                      .5, #male
                      .15, #36-50,
                      .1, #51-64,
                      .2, #65+,
                      .7, #college
                      -0.6 , #post-grad
                      .2,#ind x 36-50
                      1, #rep x 36-50,
                      .5, #ind x 51-64,
                      .5, #rep x 51-64,
                      -.2, #ind x 65+
                      1 #rep x 65+
        )
        xbeta = cces_expanded %*% coefs
        p_include = plogis(xbeta)
        sum(p_include)
        
        #################### DESIGN OUTCOME MODEL ##################
        coefs_outcome = coefs
        #p(D)
        coefs_outcome[,1] = c(8, #intercept #5 w race
                              -3,#-.5, #selection of indep pos
                              -5,# -.8, #selection of R pos
                              -.3, #male
                              -.5, #36-50,
                              -.1, #51-64,
                              -.2, #65+,
                              .8, #college
                              .9,  #post-grad
                              -2.8,#ind x 36-50
                              -2.8, #rep x 36-50,
                              -.5, #ind x 51-64,
                              -.5, #rep x 51-64,
                              .8, #ind x 65+
                              -1 #rep x 65+
        )
        if(!bern) {
            cat(paste("Adding sd(outcome)*",round(noise, 3), "\n")) 
            #set.seed(123123)
            bound = bound_outcome(outcome = cces_expanded %*% coefs_outcome,
                                  coefs = coefs_outcome,
                                  cces_expanded = cces_expanded,
                                  noise = noise)
            #xbeta_outcome = xbeta_outcome + rnorm(nrow(cces_expanded), mean = 0, sd = sd(xbeta_outcome)*noise)
            xbeta_outcome = bound$outcome
            #coefs_outcome = bound$coefs*denom
            #summary(xbeta_outcome)
            beyond_support = check_outcome(xbeta_outcome)
        }
        
        coefs_outcome_out = bound$coefs
        
        if(min(xbeta_outcome) <0 | max(xbeta_outcome) > 1) {
            warning("Outcome beyond prob support for some units when noise is added, but should be bounded\n",
                                                                    immediate. = T)
        }
        if(bern) {
            cat(paste("Adding bernoulli noise and making outcome binary\n"))  
            xbeta_outcome = rbinom(nrow(cces), 1, xbeta_outcome) 
            cat(paste("Corr of S (one sample draw) and Y", round(cor(sample, xbeta_outcome),3)))
        }
        cat(paste("Range of outcome w/noise is\n"))
        cat(paste(summary(xbeta_outcome), "\n"))
        s = summary(lm(update(selection_model, xbeta_outcome ~ .),data = cces))
        R2_outcome = s$adj.r.squared
        cat(paste("R^2 outcome is", round(s$adj.r.squared,3), "\n"))
        cat(paste("Mean scaled outcome (target) is", round(mean(xbeta_outcome)*100,3), "\n"))
        cat(paste("Corr of sampling prob and outcome ", round(cor(xbeta_outcome, p_include),3),"\n"))
        cces$outcome = xbeta_outcome
        
    }
    
}

    if(coverage_eval) {
        formula_ps <- selection_model
    } else {
        formula_ps <- ~recode_age_3way + recode_pid_3way + recode_female
    }
    
    ######### Make STRATA variable in CCES and Pew ############
    cces <- bind_cols(cces, cces %>%
                          unite("strata", all.vars(formula_ps), remove = FALSE) %>%
                          unite("strata_reduc", all.vars(formula_ps_reduc),
                                remove = FALSE) %>%
                          unite("strata_all", all.vars(formula_ps_all)) %>%
                          dplyr::select(strata, strata_reduc, strata_all))
    
    #weirdly this is producing still bias w ps on the correct formula apparently maybe because we are dropping the one category  with unite so im going to try this manual way:
    cces = cces %>% mutate(strata = paste(recode_pid_3way,
                                          recode_female, 
                                          recode_age_bucket,
                                          recode_educ_3way,
                                          sep = "_"))
    
    cces = cces %>% mutate(strata = paste(recode_pid_3way,
                                          recode_female, 
                                          recode_age_bucket,
                                          recode_educ_3way,
                                          sep = "_"))
    
    #cces = cces %>% select(all.vars(selection_model)) %>% mutate(strata = paste(.,sep = "_"))
    pew <- bind_cols(pew, pew %>%
                         unite("strata", all.vars(formula_ps), remove = FALSE) %>%
                         unite("strata_reduc", all.vars(formula_ps_reduc),
                               remove = FALSE) %>%
                         unite("strata_all", all.vars(formula_ps_all)) %>%
                         dplyr::select(strata, strata_reduc, strata_all))
    
    pew = pew %>% mutate(strata = paste(recode_pid_3way, recode_female, recode_age_bucket, sep = "_"))
    
    
    ############### kable_res
    selection_coefs_kable = data.frame(coefs)
        colnames(selection_coefs_kable) = "Coefficient Value"
        rownames(selection_coefs_kable) = gsub("^recode_", "", rownames(selection_coefs_kable))
        selection_coefs_kable = kable(selection_coefs_kable,
                                          format = "latex", booktabs = T,
                           caption = paste("Linear=",linear_model, "Selection Model" ))
        
        xbeta = cces_expanded %*% coefs
        p_include = plogis(xbeta)
        cat(paste("Sum of Selection Probs is:", round(sum(p_include), 3), "\n"))
        out = c(min(p_include), 
                quantile(p_include, c(0.25, 0.5, .75)), 
                max(p_include), 
                sum(p_include))
        out = as.matrix(out)
        rownames(out) =  c("Min", "25%", "Mean", "75%", "Max", "Sum")
        colnames(out) = c("Selection Probability")
        
        prob_kable = kable(round(out, 4), format = "latex", 
                           booktabs = T,
                           caption = paste("Linear=",linear_model,"Sample Inclusion Probabilities"))
        
        coefs_outcome_kable = data.frame(coefs_outcome_out)
        colnames(coefs_outcome_kable) = "Coefficient Value"
        rownames(coefs_outcome_kable) = gsub("^recode_", "", rownames(coefs_outcome_kable))
        coefs_outcome_kable = kable(coefs_outcome_kable,
                                          format = "latex", booktabs = T,
                           caption = paste("Linear=",linear_model, "Outcome Model") )
    

    return(list(R2 = R2_outcome,
                linear = linear_model,
                target = mean(cces$outcome),
                corr = cor(xbeta_outcome, p_include), 
                selection_prob_kable = prob_kable,
                coefs_outcome_kable= coefs_outcome_kable, 
                selection_coefs_kable= selection_coefs_kable))
}

```

```{r emp_SEs, include = F}
empirical_SEs <- function(sims, eval_kpop = T, return_svy_package = F, na_rm = F) {
    SEs = lapply(sims, `[[`, 2) %>% bind_rows()
    est <- lapply(sims, `[[`, 1) %>% bind_rows()
    cols = grepl("kpop|rake|post_stratification|unweighted", colnames(est))
    #cols = if(eval_kpop) { c(3:7,10:12,14:19)} else {c(3:7,10:12)}
    est =est[, cols]

    #avg SEs
    avg_SE = colMeans(SEs, na.rm = na_rm)
    avg_SE_out = rbind(avg_SE[grepl("SE_fixed$", names(avg_SE))],
                   avg_SE[grepl("SE_linear$", names(avg_SE))],
                   avg_SE[grepl("SE_quasi$", names(avg_SE))],
                   avg_SE[grepl("SE_chad", names(avg_SE))],
                   avg_SE[grepl("SVY", names(avg_SE))])
    rownames(avg_SE_out) = c("SE_fixed", "SE_linear", "SE_quasi", "SE_chad", "SE_SVY") 
    colnames(avg_SE_out) = gsub("_SE_fixed", "", colnames(avg_SE_out))
    
    #bootstrapped SEs
    boot_SE = t(as.matrix(apply(est, 2, sd)))
    SE_boot = boot_SE[, colnames(boot_SE) %in% colnames(avg_SE_out)]
    #stupid fix for non names kpop mf Ses in some sims
    good_cnames = grepl("kpop|rake|post_stratification|unweighted", colnames(avg_SE_out))
    good_cnames = colnames(avg_SE_out)[good_cnames]
    emp_SEs = rbind(avg_SE_out, SE_boot[good_cnames])
    if(rownames(emp_SEs)[nrow(emp_SEs)] == "") { rownames(emp_SEs)[nrow(emp_SEs)] = "SE_boot" }
    
    if(!return_svy_package) {
        avg_SE_out = avg_SE_out[-which(rownames(avg_SE_out) == "SE_SVY"), ]
        emp_SEs = emp_SEs[-which(rownames(emp_SEs) == "SE_SVY"), ]
    }
    
    return(list(emp_SEs =emp_SEs, 
                boot_SE = boot_SE,
                avg_SE = avg_SE_out) )    
}

```


```{r run_outcome, include = F}
r33_lin = make_outcome(noise = sqrt(2), linear_model = T)
r66_lin = make_outcome(noise = sqrt(2)*(1/2), linear_model = T)
r66 =  make_outcome(noise = sqrt(2)*(1/2),  linear_model = F)

#r66_bern = make_outcome(noise = sqrt(2)*(1/2), bern = T)

```

# Simulation Set Up

## Linear Model
### Selection Model
$p(S=1) = logit^{-1}\Big( PID(3 way) + Age(4way)+ Gender  \Big)$

More specifically:
$$p(S=1) = logit^{-1}\Big( \alpha + \beta_1 Indep + \beta_2 Rep + \beta_3 Age_{36-50} + \beta_4  Age_{51-64} + \beta_5 Age_{65+} + \beta_6 Male \Big)$$

Where coefs are chosen roughly similar to a fitted model to pew that yields a sample size around 500. Namely:
```{r, echo = F}
r33_lin$selection_coefs_kable %>%
  kable_styling(latex_options = "hold_position")
```

This yields the following sampling  probabilities

```{r, echo = F}
r33_lin$selection_prob_kable %>%
  kable_styling(latex_options = "hold_position")
```

### Outcome Model
Trying to keep things straight forward, I use the identical outcome model with coefficients chosen to roughly match the observed vote choice Democratic margin. In other words, again we have:
$$p(Vote=D) = \alpha + \beta_1 Indep + \beta_2 Rep + \beta_3 Age_{36-50} + \beta_4  Age_{51-64} + \beta_5 Age_{65+} + \beta_6 Male$$

Coefficients were chose to be realistic and to yield $\hat{y}$'s that lie within a probability range:

```{r, echo = F}
r33_lin$coefs_outcome_kable %>%
  kable_styling(latex_options = "hold_position")
```

This yields a population target  in percentage points of:
```{r, echo = F}
cat(paste0("Linear=", r33_lin$linear, " Target= ",round(r33_lin$target,4)*100, "%"))
```


I then add normally distributed noise to this outcome with mean zero and standard deviation $\sigma = sd(Y)*noise$. 

I run simulations where this noise is $\sqrt(2)$, yielding an $R^2$ of .33, and of $\frac{1}{2}*\sqrt(2)$ yielding an $R^2$ of .66. Finally, I run one last batch of simulations additionally adding noise by defining the outcome as bernoulli draws using the $\hat{y}$'s with $R^2$ of .66. This yields a $R^2$ of 0.017.

```{r, echo = F}
cat(paste0("For Linear Model w/ R2=",round(r33_lin$R2,3), " the correlation of Y with p(S=1) is ", round(r33_lin$corr,2), "\n"))
cat(paste0("For Linear Model w/ R2=",round(r66_lin$R2,3), " the correlation of Y with p(S=1) is ", round(r66_lin$corr,2), "\n"))
# cat(paste0("For R2=",round(r66_bern$R2,3), " the correlation with p(S=1) is ", 
#            round(r66_bern$corr,2), "\n"))
```


## Non-linear Model

### Selection Model

$p(S=1) = logit^{-1}\Big( PID(3way) + Age(4way)+ Gender + Educ(3way) + PID(3way)*Age(4way)\Big)$

Where coefs are chosen to yields a sample size around 500. Namely:

```{r, echo = F}
r66$selection_coefs_kable %>%
  kable_styling(latex_options = "hold_position")
```

This yields the following sampling  probabilities
```{r, echo = F}
r66$selection_prob_kable %>%
  kable_styling(latex_options = "hold_position")
```


\clearpage
### Outcome Model
Trying to keep things straight forward, I use the identical outcome model with coefficients chosen to roughly match the observed vote choice Democratic margin. In other words, again we have:
$$p(Vote=D) =  PID(3way) + Age(4way)+ Gender + Educ(3way)  + PID(3way)*Age(4way)$$
Coefficients were chose to be realistic and to yield $\hat{y}$'s that lie within a probability range:

```{r, echo = F}
r66$coefs_outcome_kable %>%
  kable_styling(latex_options = "hold_position")
```

This yields a population target  in percentage points of:
```{r, echo = F}
cat(paste0("Linear=", r66$linear, " Target= ",round(r66$target,4)*100, "%"))
```


I then add normally distributed noise to this outcome with mean zero and standard deviation $\sigma = sd(Y)*noise$. 

I run simulations where this noise is $\frac{1}{2}*\sqrt(2)$ yielding an $R^2$ of .66. 

```{r, echo = F}
cat(paste0("For Non-Linear Model w/ R2=",round(r66$R2,3), " the correlation of Y with p(S=1) is ", round(r66$corr,2), "\n"))
#cat(paste0("For R2=",round(r66$R2,3), " the correlation with p(S=1) is ", round(r66$corr,2), "\n"))
#cat(paste0("For R2=",round(r66_bern$R2,3), " the correlation with p(S=1) is ", 
#           round(r66_bern$corr,2), "\n"))
```

I set up this non-linear model with variables that have a few levels so that the intersection of $X^P$ in post-stratification is so complex that we're forced to drop units in the CCES population that have empty cells in the sample. Doing this, leads to the following:

```{r ps_drop, echo = F}
load(r66_file)
good = which(lapply(sims, function (x) return(class(x))) == "list")
temp = sims[good]
ps_dropped <- lapply(temp, `[[`, 4)
dropped_cells = lapply(ps_dropped, `[[`, 1) %>% bind_rows()
dropped_cells_reduc = lapply(ps_dropped, `[[`, 2)  %>% bind_rows()
dropped_cells_all = lapply(ps_dropped, `[[`, 3) %>% bind_rows()

cat(paste0("For Non-Linear Model w/ R2=",round(r66$R2,3), " PS must drop an average of ", round(mean(dropped_cells$sum),2),
           "units w/ a sd=", round(sd(dropped_cells$sum)),
           " which is ", round(100*(mean(dropped_cells$sum)/44932),2),"% of the population\n"))
#cat(paste0("For R2=",round(r66$R2,3), " the correlation with p(S=1) is ", round(r66$corr,2), "\n"))
#cat(paste0("For R2=",round(r66_bern$R2,3), " the correlation with p(S=1) is ", 
#           round(r66_bern$corr,2), "\n"))
```


# Results

## Linear Model

Bias and Standard Errors for the linear model with two levels of noise added  ($R^2=0.33$ & $R^2=0.66$)). 
```{r r33_lin_res, echo = F}
load(r33_file_lin)
outcome_obj= r33_lin
good = which(lapply(sims, function (x) return(class(x))) == "list")

r33_emp_SEs = empirical_SEs(sims = sims)

kable(round(bias, 3), format = "latex", booktabs = T,
      caption = paste0("Linear=",outcome_obj$linear, " Bias \\textbf{in Percent} across ", length(good),
                       " sims: All Methods (Target = ", 
                       round(mean(outcome),3)*100, "), $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")


kable(round(r33_emp_SEs$emp_SEs[,c(5:ncol(r33_emp_SEs$emp_SEs))]*100,3), 
      format = "latex", booktabs = T, 
      caption = paste("Linear=",outcome_obj$linear, "Empirical SE Results \\textbf{in Percent}: Avg SE + Boot SE (sd(estimate)) ", 
                          length(good), "sims; $R^2$ on Outcome = ", round(r33_lin$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")


kable(round(SE_coverage[-5, c(5:ncol(SE_coverage))], 3), format = "latex", booktabs = T,
          caption = paste("Linear=",outcome_obj$linear, "SE Coverage Results: Kpop", 
                          length(good), "sims; $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")

rm(sims, gg_out, table, outcome, bias, SE_coverage)

```

```{r r66_lin_res, echo=F}
load(r66_file_lin)
outcome_obj = r66_lin
good = which(lapply(sims, function (x) return(class(x))) == "list")

r66_emp_SEs = empirical_SEs(sims = sims)

kable(round(bias, 3), format = "latex", booktabs = T,
      caption = paste0("Linear=",outcome_obj$linear, " Bias \\textbf{in Percent} across ", length(good),
      " sims: All Methods (Target = ", round(mean(outcome),3)*100, "), $R^2$ on Outcome = ",
      round(r66_lin$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")

kable(round(r66_emp_SEs$emp_SEs[,c(5:ncol(r66_emp_SEs$emp_SEs))]*100,3), format = "latex", booktabs = T, 
      caption = paste("Linear=",outcome_obj$linear, "Empirical SE Results \\textbf{in Percent}: Avg SE + Boot SE (sd(estimate)) ", 
                          length(good), "sims; $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")

kable(round(SE_coverage[-5, c(5:ncol(SE_coverage))], 3), format = "latex", booktabs = T,
          caption = paste("Linear=",outcome_obj$linear, "SE Coverage Results: Kpop",
                          length(good), "sims; $R^2$ on Outcome = ", round(outcome_obj$R2, 3)))%>%
  kable_styling(latex_options = "hold_position")
rm(sims, gg_out, table, outcome, bias, SE_coverage)
```


```{r, echo = F, eval = F, include = F}
load(r66_bern_file_lin)

good = which(lapply(sims, function (x) return(class(x))) == "list")

r66_bern_emp_SEs = empirical_SEs(sims = sims)

kable(round(bias, 3), format = "latex", booktabs = T,
      caption = paste0("Bias \\textbf{in Percent} across ", length(good),
      " sims: All Methods (Target = ", round(mean(outcome),3)*100, "), $R^2$ on Outcome = ",
      round(r66_bern$R2, 3)))

kable(round(r66_bern_emp_SEs$emp_SEs[,c(5:ncol(r66_bern_emp_SEs$emp_SEs))]*100,3), 
      format = "latex", booktabs = T, 
      caption = paste("Empirical SE Results \\textbf{in Percent}: Avg SE + Boot SE (sd(estimate)) ", 
                          length(good), "sims; $R^2$ on Outcome = ", round(r66_bern_lin$R2, 3)))

kable(round(SE_coverage[-5, c(5:ncol(SE_coverage))], 3), format = "latex", booktabs = T,
          caption = paste("SE Coverage Results: Kpop",
                          length(good), "sims; $R^2$ on Outcome = ", round(r66_bern_lin$R2, 3)))


```

\clearpage


## Non-linear Model

Bias and Standard Errors for the non-linear model with one level of noise added ($R^2=0.66$). Note that "kpop_reduc" is the kpop run without any constraints added, but with the variables in the selection model (pid, education, gender, age) the only data provided to kpop. The other kpop methods have constraints appended to match the variables in each of the raking methods."kpop_mf" refers to the automated mean first routine which appends an m optimal number of constraints which are the m left singular vectors of the svd of all the variables. "kpop_conv" refers to default kpop with teh full data, but forcing ebalance convergence.

```{r non_lin_res, echo = F, warnings = F}
load(r66_file)
outcome_obj = r66
good = which(lapply(sims, function (x) return(class(x))) == "list")

r66_emp_SEs = suppressWarnings(empirical_SEs(sims = sims[good], na_rm = T))
#manual fix for issue w not naming mf cols when SEs fail in sims
r66_emp_SEs$avg_SE = r66_emp_SEs$avg_SE[, -ncol(r66_emp_SEs$avg_SE)]
r66_emp_SEs$emp_SEs = r66_emp_SEs$emp_SEs[, -ncol(r66_emp_SEs$emp_SEs)]

est <- lapply(sims[good], `[[`, 1) %>% bind_rows()
cols = grepl("kpop|rake|post_stratification|unweighted", colnames(est))
bias = colMeans(est[, cols], na.rm = T)
bias = bias - mean(outcome)
bias = data.frame(bias = t(t(bias))*100)
bias = bias %>% arrange(desc(abs(bias)))

#more shit for this stupid extra column in the SEs
SEs_fix = lapply(sims[good], `[[`, 2) %>% bind_rows()
SEs_fix = SEs_fix[, -c((ncol(SEs_fix)-3):ncol(SEs_fix))]
SE_coverage = all_SE_coverage(sims[good], truth = mean(outcome),SEs_overwrite = SEs_fix, drop_NA = T)
SE_coverage = SE_coverage$coverage

kable(round(bias, 3), format = "latex", booktabs = T,
      caption = paste0("Linear=",outcome_obj$linear," Bias \\textbf{in Percent} across ", length(good),
                       " sims: All Methods (Target = ", 
                       round(mean(outcome),3)*100, "), $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")


kable(round(r66_emp_SEs$emp_SEs[,c(5:ncol(r66_emp_SEs$emp_SEs))]*100,3), 
      format = "latex", booktabs = T, 
      caption = paste("Linear=",outcome_obj$linear,"Empirical SE Results \\textbf{in Percent}: Avg SE + Boot SE (sd(estimate)) ", 
                          length(good), "sims; $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")


kable(round(SE_coverage[-5, c(5:ncol(SE_coverage))], 3), format = "latex", booktabs = T,
          caption = paste("Linear=",outcome_obj$linear,"SE Coverage Results: Kpop", 
                          length(good), "sims; $R^2$ on Outcome = ", round(outcome_obj$R2, 3))) %>%
  kable_styling(latex_options = "hold_position")


 # margin_sim = mean(outcome)*100
 # est = lapply(sims[good], `[[`, 1) %>% bind_rows()
# ggplot(data = gg_out$data,
#                 aes(x = estimator_name, y = margin)) +
#     geom_boxplot(alpha = 0.2) +
#     geom_hline(yintercept = margin_sim) +
#     theme_bw() +
#     xlab("") +
#     ylab("Modeled Vote Margin") +
#     annotate(geom = "text", x = 0.85, y = margin_sim+0.25, size = 2.7, angle = 90,
#              label = "True Target\nPopulation\nMargin", hjust = 0) +
#     ggtitle(paste0(nrow(est)," sims w/avg n_samp =", round(mean(est$n)), " Non-linear Model R2=", round(r66$R2.2))) +
#     theme(panel.grid.major.x = element_blank(),
#           axis.text.x = element_text(angle = 45, hjust = 1))
# 
# table

length(sims)
fail = sims[-good]
#kpop all fails
fail[1]
#rake fails
fail[2]


la = lapply(sims[good], `[[`, 1) %>% bind_rows()

mean(la$bbr)
mean(la$b_out)
mean(la$b)
la$b_out
la$numdims
la$numdims
plot(density(la$kpop))

plot(density(la$kpop_reduc))

mean(outcome)
check_sample = lapply(sims[good], `[[`, 5) %>% bind_rows()
check_sample$bad_sample    
```
